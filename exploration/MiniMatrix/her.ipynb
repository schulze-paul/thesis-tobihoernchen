{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import time\n",
                "import json\n",
                "from alpyne.client.alpyne_client import AlpyneClient\n",
                "from stable_baselines3 import DQN, HerReplayBuffer\n",
                "from stable_baselines3.common.utils import set_random_seed\n",
                "from stable_baselines3.common.env_util import make_vec_env\n",
                "from gym import GoalEnv\n",
                "\n",
                "sys.path.append(\"../..\")\n",
                "from thesis.envs.matrix_routing_multiagent import MatrixRoutingMA\n",
                "from thesis.policies.routing_attention import RoutingFE_offPolicy\n",
                "from thesis.policies.ppo_ac_attention import AttentionACPolicy\n",
                "\n",
                "seed = 42\n",
                "set_random_seed(seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "models_dir = \"../../models/MiniMatrix_Routing_MA\"\n",
                "logdir = \"../../logs/MiniMatrix_Routing_MA\"\n",
                "fleetsize = 6\n",
                "max_fleetsize = 10\n",
                "run_name = f\"HER-{fleetsize}-{max_fleetsize}-{time.strftime('%d_%m-%H_%M_%S')}-{seed}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "env_args = dict(\n",
                "        reward_target = 1, \n",
                "        reward_distance = 0.05,\n",
                "        reward_block = -0.5, \n",
                "        dispatchinginterval=120,\n",
                "        routinginterval = 2,\n",
                "        withCollisions = True,\n",
                "        #blockTimeout = ,\n",
                "        includeNodesInReach = True,\n",
                "        dispatcher_args=dict(distance=6)\n",
                "    )\n",
                "\n",
                "alg_args = dict(\n",
                "    #learning_rate = 3e-3,\n",
                "    #buffer_size = 100000\n",
                ")\n",
                "fe_args = dict(\n",
                "    max_fleetsize=max_fleetsize,\n",
                "    embed_dim = 64,\n",
                "    n_heads = 8,\n",
                "    depth = 8\n",
                ")\n",
                "net_arch = dict(qf = [], pi = [])\n",
                "\n",
                "hparams = dict(\n",
                "    fleetsize = fleetsize,\n",
                "    max_fleetsize = max_fleetsize,\n",
                "    env_args = env_args,\n",
                "    alg_args = alg_args,\n",
                "    fe_args = fe_args,\n",
                "    net_arch = net_arch\n",
                ")\n",
                "with open(f\"{models_dir}/{run_name}.json\", 'w') as outfile:\n",
                "    json.dump(hparams, outfile, indent = 3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from gym import spaces\n",
                "from alpyne.data.spaces import Observation\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "class MatrixRoutingMAGoal(MatrixRoutingMA, GoalEnv):\n",
                "    \n",
                "    def _convert_from_observation(self, observation:Observation):\n",
                "        obs = MatrixRoutingMA._convert_from_observation(self,observation=observation)\n",
                "        obs = obs.reshape((self.max_fleetsize, len(obs)//self.max_fleetsize))\n",
                "        return dict(\n",
                "            observation = obs.flatten(),\n",
                "            desired_goal= obs[0, 7:9].flatten(),\n",
                "            achieved_goal= obs[0, 5:7].flatten(),\n",
                "        )\n",
                "\n",
                "    def _get_observation_space(self) -> spaces.Dict:\n",
                "        spc = MatrixRoutingMA._get_observation_space(self)\n",
                "        spc\n",
                "        return spaces.Dict(\n",
                "            dict(\n",
                "                observation = spc,\n",
                "                desired_goal= spaces.Box(low=0, high=1, shape=(2,)),\n",
                "                achieved_goal= spaces.Box(low=0, high=1, shape=(2,))\n",
                "            )\n",
                "        )\n",
                "\n",
                "    def step(self, action):\n",
                "        obs, reward, done, info = MatrixRoutingMA.step(self, action)\n",
                "        reward = self.compute_reward(obs[\"achieved_goal\"],obs[\"desired_goal\"], info)\n",
                "        return obs, float(reward), done, info\n",
                "\n",
                "    def compute_reward(self, achieved_goal, desired_goal, info) -> float:\n",
                "        return np.multiply(1, np.all(np.isclose(achieved_goal, desired_goal, 0.01), axis = -1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\alpyne\\client\\utils.py:124: UserWarning: Unzipping to temporary directory (C:\\Users\\Wegma\\AppData\\Local\\Temp\\alpyne_27233_ap4y4orb)\n",
                        "  warn(f\"Unzipping to temporary directory ({tmp_dir})\")\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "\n",
                "client = AlpyneClient(\"../../envs/MiniMatrix.zip\", port=51142)\n",
                "\n",
                "env = MatrixRoutingMAGoal(\n",
                "    max_seconds = 10*60, \n",
                "    fleetsize = fleetsize, \n",
                "    max_fleetsize=max_fleetsize, \n",
                "    config_args = env_args,\n",
                "    counter = i,\n",
                "    client = client\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "model =DQN(\n",
                "    \"MultiInputPolicy\",\n",
                "    env, \n",
                "    tensorboard_log= logdir,\n",
                "    device = \"cuda\",\n",
                "    policy_kwargs=dict(\n",
                "        #net_arch = net_arch,\n",
                "        features_extractor_class=RoutingFE_offPolicy, \n",
                "        features_extractor_kwargs=fe_args\n",
                "        ),\n",
                "    replay_buffer_class=HerReplayBuffer,    \n",
                "    replay_buffer_kwargs=dict(\n",
                "        max_episode_length=10*60,\n",
                "    ),\n",
                "    buffer_size = 60000,\n",
                "    optimize_memory_usage=True,\n",
                "    **alg_args,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32md:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\her.ipynb Zelle 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Master/Masterarbeit/thesis/exploration/MiniMatrix/her.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m TIMESTEPS \u001b[39m=\u001b[39m \u001b[39m50000\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Master/Masterarbeit/thesis/exploration/MiniMatrix/her.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m15\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Master/Masterarbeit/thesis/exploration/MiniMatrix/her.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49mTIMESTEPS, reset_num_timesteps\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, tb_log_name\u001b[39m=\u001b[39;49mrun_name)\u001b[39m#,callback=MiniMatrixCallback())\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Master/Masterarbeit/thesis/exploration/MiniMatrix/her.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodels_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrun_name\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mTIMESTEPS \u001b[39m*\u001b[39m i\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:264\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    252\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    253\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    262\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    265\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    266\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    267\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    268\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[0;32m    269\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[0;32m    270\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[0;32m    271\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    272\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[0;32m    273\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    274\u001b[0m     )\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:344\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    341\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    343\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 344\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[0;32m    345\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[0;32m    346\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[0;32m    347\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[0;32m    348\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    349\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[0;32m    350\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[0;32m    351\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    352\u001b[0m     )\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:574\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor\u001b[39m.\u001b[39mreset_noise(env\u001b[39m.\u001b[39mnum_envs)\n\u001b[0;32m    573\u001b[0m \u001b[39m# Select action randomly or according to policy\u001b[39;00m\n\u001b[1;32m--> 574\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39;49mnum_envs)\n\u001b[0;32m    576\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m    577\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(actions)\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:405\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._sample_action\u001b[1;34m(self, learning_starts, action_noise, n_envs)\u001b[0m\n\u001b[0;32m    400\u001b[0m     unscaled_action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_envs)])\n\u001b[0;32m    401\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[39m# Note: when using continuous actions,\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[39m# we assume that the policy uses tanh to scale the action\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[39m# We use non-deterministic action in the case of SAC, for TD3, it does not matter\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m     unscaled_action, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_last_obs, deterministic\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    407\u001b[0m \u001b[39m# Rescale the action from [low, high] to [-1, 1]\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space, gym\u001b[39m.\u001b[39mspaces\u001b[39m.\u001b[39mBox):\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:248\u001b[0m, in \u001b[0;36mDQN.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    246\u001b[0m         action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample())\n\u001b[0;32m    247\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m     action, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mpredict(observation, state, episode_start, deterministic)\n\u001b[0;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m action, state\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\common\\policies.py:338\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    335\u001b[0m observation, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_to_tensor(observation)\n\u001b[0;32m    337\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 338\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(observation, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[0;32m    339\u001b[0m \u001b[39m# Convert to numpy\u001b[39;00m\n\u001b[0;32m    340\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\dqn\\policies.py:178\u001b[0m, in \u001b[0;36mDQNPolicy._predict\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, obs: th\u001b[39m.\u001b[39mTensor, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_net\u001b[39m.\u001b[39;49m_predict(obs, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\dqn\\policies.py:69\u001b[0m, in \u001b[0;36mQNetwork._predict\u001b[1;34m(self, observation, deterministic)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, observation: th\u001b[39m.\u001b[39mTensor, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m---> 69\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(observation)\n\u001b[0;32m     70\u001b[0m     \u001b[39m# Greedy action\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     action \u001b[39m=\u001b[39m q_values\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\dqn\\policies.py:66\u001b[0m, in \u001b[0;36mQNetwork.forward\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, obs: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m     60\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m    Predict the q-values.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[39m    :param obs: Observation\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m    :return: The estimated Q-Value for each action.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_net(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(obs))\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\stable_baselines3\\common\\policies.py:129\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mNo features extractor was set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m preprocessed_obs \u001b[39m=\u001b[39m preprocess_obs(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space, normalize_images\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize_images)\n\u001b[1;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures_extractor(preprocessed_obs)\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[1;32md:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\routing_attention.py:125\u001b[0m, in \u001b[0;36mRoutingFE_offPolicy.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 125\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(x)\n\u001b[0;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m x[:, \u001b[39m0\u001b[39m]\n",
                        "File \u001b[1;32md:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\routing_attention.py:105\u001b[0m, in \u001b[0;36mRoutingFE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m# reshaped = reshaped.masked_fill(self.mask.repeat(1, 1, self.n_obs_per_agv) == 0, 0)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedd(reshaped)\n\u001b[1;32m--> 105\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mablocks(x)\n\u001b[0;32m    106\u001b[0m \u001b[39m# x = x.masked_fill(self.actionmask.repeat(1, 1, self.embed_dim) == 0, 0)\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
                        "File \u001b[1;32mc:\\Users\\Wegma\\.conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[1;32md:\\Master\\Masterarbeit\\thesis\\exploration\\MiniMatrix\\../..\\thesis\\policies\\routing_attention.py:44\u001b[0m, in \u001b[0;36mAttentionBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(attended \u001b[39m+\u001b[39m x)\n\u001b[0;32m     43\u001b[0m fedforward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mff(x)\n\u001b[1;32m---> 44\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(fedforward \u001b[39m+\u001b[39;49m x)\n\u001b[0;32m     45\u001b[0m \u001b[39m# x = x * self.fn_mask().detach()\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
                    ]
                }
            ],
            "source": [
                "TIMESTEPS = 50000\n",
                "for i in range(1, 15):\n",
                "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=run_name)#,callback=MiniMatrixCallback())\n",
                "    model.save(f\"{models_dir}/{run_name}-{TIMESTEPS * i}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 ('thesis')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "dc7f4105f9f5e395f215a7643dd52717d50b308583dcde27027fbaaaba0d8cea"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
